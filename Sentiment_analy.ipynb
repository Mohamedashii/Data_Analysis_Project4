{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m3N2iLqXHGTV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"NLP_Sentiment_Analysis\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "data = [\n",
        "    (\"I absolutely loved this movie, it was fantastic!\", 1.0),\n",
        "    (\"The plot was boring and the acting was terrible.\", 0.0),\n",
        "    (\"Great cinematography, but the story was weak.\", 0.0),\n",
        "    (\"An absolute masterpiece, highly recommended.\", 1.0),\n",
        "    (\"I wasted my time watching this. Extremely disappointed.\", 0.0),\n",
        "    (\"The best film I have seen this year!\", 1.0)\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data, [\"text\", \"label\"])\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agBcEcMPHYae",
        "outputId": "f13ce6b5-e164-4733-a6a8-0fb6ec806cd3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------+-----+\n",
            "|text                                                   |label|\n",
            "+-------------------------------------------------------+-----+\n",
            "|I absolutely loved this movie, it was fantastic!       |1.0  |\n",
            "|The plot was boring and the acting was terrible.       |0.0  |\n",
            "|Great cinematography, but the story was weak.          |0.0  |\n",
            "|An absolute masterpiece, highly recommended.           |1.0  |\n",
            "|I wasted my time watching this. Extremely disappointed.|0.0  |\n",
            "|The best film I have seen this year!                   |1.0  |\n",
            "+-------------------------------------------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "\n",
        "\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "\n",
        "\n",
        "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "\n",
        "\n",
        "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, lr])"
      ],
      "metadata": {
        "id": "eOq88m26Hbyc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "model = pipeline.fit(train_data)\n",
        "\n",
        "predictions = model.transform(test_data)\n",
        "predictions.select(\"text\", \"probability\", \"prediction\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv1zoCDxIpo9",
        "outputId": "69d8b2df-3bda-4528-e876-5ce69999548e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+----------+\n",
            "|                text|         probability|prediction|\n",
            "+--------------------+--------------------+----------+\n",
            "|The plot was bori...|[0.39553605915909...|       1.0|\n",
            "|An absolute maste...|[0.39553605915909...|       1.0|\n",
            "+--------------------+--------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Model Accuracy (Area under ROC): {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXyapGBcItQs",
        "outputId": "9b33f05f-7460-4622-c9fd-b25a2061353a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy (Area under ROC): 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mnP3d_0rIwdW"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}